{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 104/104 [00:07<00:00, 13.94it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 20.10it/s]\n",
      "100%|██████████| 104/104 [00:04<00:00, 20.89it/s]\n",
      "100%|██████████| 104/104 [00:04<00:00, 20.94it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 20.22it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 20.50it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 20.69it/s]\n",
      "100%|██████████| 104/104 [00:04<00:00, 21.13it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 20.27it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 18.96it/s]\n",
      "100%|██████████| 104/104 [00:04<00:00, 21.15it/s]\n",
      "100%|██████████| 104/104 [00:04<00:00, 20.97it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 20.04it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 18.24it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 19.70it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 19.59it/s]\n",
      "100%|██████████| 104/104 [00:06<00:00, 16.27it/s]\n",
      "100%|██████████| 60/60 [00:02<00:00, 22.31it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 18.59it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 19.95it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 18.25it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 19.31it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 18.93it/s]\n",
      "100%|██████████| 104/104 [00:05<00:00, 18.46it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 48.88it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 51.16it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 53.10it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.64it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 51.69it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.20it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 46.71it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.13it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 47.44it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 51.52it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 50.59it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 49.47it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 50.16it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 50.20it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
    "    return np.hstack((mfcc, mel))\n",
    "\n",
    "# directories in which datset is present\n",
    "RAVDESS_DIR = 'ravdess_dataset'\n",
    "TESS_DIR = 'tess_dataset'\n",
    "\n",
    "# Function to extract emotion from RAVDESS filename\n",
    "def extract_ravdess_emotion(filename):\n",
    "    return filename.split('-')[2]\n",
    "\n",
    "# Function to extract emotion from TESS filename\n",
    "def extract_tess_emotion(filename):\n",
    "    emotion_str = filename.split('_')[-1].split('.')[0]\n",
    "    return emotion_str\n",
    "\n",
    "# Function to process dataset directory\n",
    "def process_directory(directory, emotion_map, extract_emotion_func):\n",
    "    features, labels = [], []\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in tqdm(files):\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                emotion_key = extract_emotion_func(file)\n",
    "                if emotion_key in emotion_map:\n",
    "                    emotion = emotion_map[emotion_key]\n",
    "                    feature = extract_features(file_path)\n",
    "                    features.append(feature)\n",
    "                    labels.append(emotion)\n",
    "                else:\n",
    "                    print(f\"Warning: Emotion '{emotion_key}' not found in emotion map.\")\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Define emotion mappings for both datasets\n",
    "ravdess_emotion_map = {\n",
    "    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
    "    '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'\n",
    "}\n",
    "\n",
    "tess_emotion_map = {\n",
    "    'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3,\n",
    "    'ps': 4, 'sad': 5, 'neutral': 6\n",
    "}\n",
    "\n",
    "# Create a reverse mapping for TESS emotions(to make the wors back to integer)\n",
    "reverse_tess_emotion_map = {v: k for k, v in tess_emotion_map.items()}\n",
    "\n",
    "# Process RAVDESS and TESS datasets\n",
    "X_ravdess, y_ravdess = process_directory(RAVDESS_DIR, ravdess_emotion_map, extract_emotion_func=extract_ravdess_emotion)\n",
    "X_tess, y_tess = process_directory(TESS_DIR, tess_emotion_map, extract_emotion_func=extract_tess_emotion)\n",
    "\n",
    "# Convert y_tess back to emotion names\n",
    "y_tess_emotion_names = [reverse_tess_emotion_map[label] for label in y_tess]\n",
    "\n",
    "# Combine datasets\n",
    "X = np.vstack((X_ravdess, X_tess))\n",
    "y = np.hstack((y_ravdess, y_tess_emotion_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Dataset and DataLoader\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = EmotionDataset(X_train, y_train)\n",
    "test_dataset = EmotionDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "model = EmotionClassifier(input_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.40913415794482 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(\"Accuracy:\", accuracy*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7355391573434896\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.99      0.77      0.87       621\n",
      "        calm       0.35      0.94      0.51       301\n",
      "     disgust       0.94      0.74      0.83       473\n",
      "        fear       1.00      0.99      0.99       320\n",
      "     fearful       0.37      0.49      0.42       301\n",
      "       happy       0.72      0.77      0.74       621\n",
      "     neutral       1.00      0.68      0.81       470\n",
      "          ps       1.00      0.99      1.00       320\n",
      "         sad       0.86      0.59      0.70       621\n",
      "   surprised       0.35      0.19      0.24       153\n",
      "\n",
      "    accuracy                           0.74      4201\n",
      "   macro avg       0.76      0.72      0.71      4201\n",
      "weighted avg       0.81      0.74      0.75      4201\n",
      "\n",
      "Test Accuracy: 0.7040913415794482\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.94      0.72      0.82       155\n",
      "        calm       0.36      0.95      0.52        75\n",
      "     disgust       0.88      0.66      0.75       119\n",
      "        fear       1.00      0.99      0.99        80\n",
      "     fearful       0.31      0.44      0.36        75\n",
      "       happy       0.68      0.73      0.70       155\n",
      "     neutral       1.00      0.69      0.81       118\n",
      "          ps       1.00      0.96      0.98        80\n",
      "         sad       0.82      0.60      0.69       155\n",
      "   surprised       0.16      0.08      0.10        39\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.71      0.68      0.67      1051\n",
      "weighted avg       0.78      0.70      0.72      1051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in data_loader:\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return accuracy_score(all_labels, all_preds), classification_report(all_labels, all_preds, target_names=label_encoder.classes_)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_accuracy, train_classification_report = evaluate(model, train_loader)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Training Classification Report:\")\n",
    "print(train_classification_report)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy, test_classification_report = evaluate(model, test_loader)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Classification Report:\")\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'emotion_classifier.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to predict emotion of an external audio (optional part)\n",
    "import pickle\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "model = EmotionClassifier(input_dim, num_classes)\n",
    "model.load_state_dict(torch.load('emotion_classifier.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Define the label encoder with the same labels used during training\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['angry', 'disgust', 'fear', 'happy', 'ps', 'sad', 'neutral', 'calm', 'surprised']))\n",
    "\n",
    "# Function to extract MFCC and MEL spectrogram features\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
    "    return np.hstack((mfcc, mel))\n",
    "\n",
    "# Function to predict emotion from an audio file\n",
    "def predict_emotion(file_path):\n",
    "    features = extract_features(file_path)\n",
    "    features = scaler.transform([features])  # Normalize the features\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    emotion = label_encoder.inverse_transform(predicted.numpy())[0]\n",
    "    return emotion\n",
    "\n",
    "# Function to load the scaler used during training\n",
    "def load_scaler(scaler_path):\n",
    "    import pickle\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    return scaler\n",
    "\n",
    "# Load the scaler used during training\n",
    "scaler = load_scaler('scaler.pkl')\n",
    "\n",
    "# Get user input for the audio file path\n",
    "file_path = input(\"Enter the path to the audio file: \")\n",
    "\n",
    "# Predict the emotion\n",
    "predicted_emotion = predict_emotion(file_path)\n",
    "print(f\"The predicted emotion is: {predicted_emotion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
